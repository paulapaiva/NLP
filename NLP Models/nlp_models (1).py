# -*- coding: utf-8 -*-
"""NLP Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VukFZTQaNgel-OYmAJxQTjVjzh9mkMvT
"""

!pip install transformers accelerate --quiet

import pandas as pd
from transformers import pipeline
import re

df = pd.read_csv("/content/spam.csv")

df = df.sample(100, random_state=42).reset_index(drop=True)
df

def cleaning(text):
    text = re.sub(r'\s+', ' ', str(text)).strip()
    return text

df["cleaned_text"] = df["text"].apply(cleaning)

generator = pipeline("text-generation", model="distilgpt2")

def classify_email_with_llm(text):
    prompt = f"Email: {text}\nLabel this as SPAM or HAM:\n"
    response = generator(prompt, max_new_tokens=10)[0]["generated_text"]
    if "spam" in response.lower():
        return "spam"
    else:
        return "ham"

df["llm_prediction"] = df["cleaned_text"].apply(classify_email_with_llm)

print(df[["text", "llm_prediction"]].head())

"""Exercise 2"""

!pip install -q streamlit pyngrok transformers

from pathlib import Path

chatbot_code = """
import streamlit as st
from transformers import pipeline

st.set_page_config(page_title="Simple Chatbot")

st.title("Chatbot")

# Load a small model for text generation
@st.cache_resource
def load_model():
    return pipeline("text-generation", model="distilgpt2")

generator = load_model()

# User input
user_input = st.text_input("You:")

if user_input:
    response = generator(user_input, max_length=50, num_return_sequences=1)[0]["generated_text"]
    st.write("Bot:", response)
"""

Path("app.py").write_text(chatbot_code)

!ngrok config add-authtoken 2zaiEfjQvpHWn63m29SZkdjweYe_41PJYwcyoRCJX5dX2rncj

from pyngrok import ngrok
import threading
import time
import os

def run():
    os.system("streamlit run app.py")

thread = threading.Thread(target=run)
thread.start()

time.sleep(5)

public_url = ngrok.connect(addr=8501)
print(f"chatbot live: {public_url}")