# -*- coding: utf-8 -*-
"""Sentiment Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DBjbULEwdEu0rxr10EookEenbpn8yVDW
"""

!pip install transformers --quiet

import pandas as pd
import nltk
import re
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from transformers import pipeline

nltk.download('vader_lexicon')
nltk.download('stopwords')
stopwords = nltk.corpus.stopwords.words('english')

df = pd.read_csv('tweets-data.csv')
df = df.sample(500, random_state=42).reset_index(drop=True)

df

def clean_text(text):
    text = re.sub(r'http\S+', '', str(text))
    text = re.sub(r'@\w+|#', '', text)
    text = re.sub(r'[^A-Za-z\s]', '', text)
    text = text.lower()
    words = [word for word in text.split() if word not in stopwords]
    return ' '.join(words)

df['cleaned_tweets'] = df['Tweets'].apply(clean_text)

"""Lexicon based

"""

sia = SentimentIntensityAnalyzer()

def get_sentiment(text):
    score = sia.polarity_scores(text)['compound']
    if score >= 0.05:
        label = 'positive'
    elif score <= -0.05:
        label = 'negative'
    else:
        label = 'neutral'
    return pd.Series([score, label])

df[['sentiment_score', 'sentiment_label']] = df['cleaned_tweets'].apply(get_sentiment)

# results
print(df[['Tweets', 'cleaned_tweets', 'sentiment_score', 'sentiment_label']].head())

"""Machine Learning"""

sentiment_classifier = pipeline("sentiment-analysis")

results = sentiment_classifier(df['cleaned_tweets'].tolist(), truncation=True)


results